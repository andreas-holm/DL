{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "import pickle\n",
    "import keras \n",
    "import numpy\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-f798d2caf55d>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-f798d2caf55d>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    #     network_input, network_output = prepare_sequence\u001b[0m\n\u001b[1;37m                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    " def train_network():\n",
    "#     notes = get_notes()\n",
    "#     n_vocab = len(set(notes))\n",
    "    \n",
    "#     network_input, network_output = prepare_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    sequence_length = 100   #det här kan vi gärna ändra\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    note_to_int = dict((note,number) for number,note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    for i in range(0,len(notes)-sequence_length,1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i+sequence_length]\n",
    "        \n",
    "        network_input.append([note_to_int[char] for char in sequence_in ])\n",
    "        \n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length,1))\n",
    "    \n",
    "    network_input = network_input /float(n_vocab)\n",
    "    \n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    \n",
    "    return(network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    notes=[]\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = None\n",
    "        \n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "\n",
    "\n",
    "\n",
    "        if parts:\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            #den ena är accord, t.ex. B5, den andra är siffror, t.ex 11.2\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                #print('.'.join(str(n) for n in element.normalOrder))\n",
    "                \n",
    "\n",
    "        with open('data/notes','wb') as filepath:\n",
    "            pickle.dump(notes, filepath)\n",
    "            \n",
    "    return notes\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512,input_shape=(network_input.shape[1],network_input.shape[2]),return_sequences=True))    \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,network_input,network_output):\n",
    "    filepath = \"weights-improvement-{epoch:02d}--{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor = 'loss',\n",
    "        verbose = 0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=100,batch_size = 64, callbacks=callbacks_list)\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5370/5370 [==============================] - 168s 31ms/step - loss: 4.5632\n",
      "Epoch 2/100\n",
      "5370/5370 [==============================] - 179s 33ms/step - loss: 4.3700\n",
      "Epoch 3/100\n",
      "5370/5370 [==============================] - 174s 32ms/step - loss: 4.2771\n",
      "Epoch 4/100\n",
      "5370/5370 [==============================] - 178s 33ms/step - loss: 4.2333\n",
      "Epoch 5/100\n",
      "5370/5370 [==============================] - 175s 33ms/step - loss: 4.1722\n",
      "Epoch 6/100\n",
      "5370/5370 [==============================] - 180s 34ms/step - loss: 4.1161\n",
      "Epoch 7/100\n",
      "5370/5370 [==============================] - 171s 32ms/step - loss: 4.0283\n",
      "Epoch 8/100\n",
      "5370/5370 [==============================] - 169s 31ms/step - loss: 3.9168\n",
      "Epoch 9/100\n",
      "5370/5370 [==============================] - 166s 31ms/step - loss: 3.7680\n",
      "Epoch 10/100\n",
      "5370/5370 [==============================] - 167s 31ms/step - loss: 3.6260\n",
      "Epoch 11/100\n",
      "5370/5370 [==============================] - 171s 32ms/step - loss: 3.4444\n",
      "Epoch 12/100\n",
      "5370/5370 [==============================] - 172s 32ms/step - loss: 3.2468\n",
      "Epoch 13/100\n",
      "5370/5370 [==============================] - 169s 31ms/step - loss: 3.0439\n",
      "Epoch 14/100\n",
      "5370/5370 [==============================] - 167s 31ms/step - loss: 2.8687\n",
      "Epoch 15/100\n",
      "5370/5370 [==============================] - 171s 32ms/step - loss: 2.6260\n",
      "Epoch 16/100\n",
      "5370/5370 [==============================] - 168s 31ms/step - loss: 2.4014\n",
      "Epoch 17/100\n",
      "5370/5370 [==============================] - 168s 31ms/step - loss: 2.2434\n",
      "Epoch 18/100\n",
      "5370/5370 [==============================] - 169s 32ms/step - loss: 2.0605\n",
      "Epoch 19/100\n",
      "5370/5370 [==============================] - 170s 32ms/step - loss: 1.8863\n",
      "Epoch 20/100\n",
      "5370/5370 [==============================] - 166s 31ms/step - loss: 1.7751\n",
      "Epoch 21/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 1.5723\n",
      "Epoch 22/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 1.4522\n",
      "Epoch 23/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 1.3006\n",
      "Epoch 24/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 1.1811\n",
      "Epoch 25/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 1.0245\n",
      "Epoch 26/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.9923\n",
      "Epoch 27/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.8279\n",
      "Epoch 28/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.7467\n",
      "Epoch 29/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.6184\n",
      "Epoch 30/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.5675\n",
      "Epoch 31/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.5001\n",
      "Epoch 32/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.4169\n",
      "Epoch 33/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.3827\n",
      "Epoch 34/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.3515\n",
      "Epoch 35/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.2916\n",
      "Epoch 36/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.2833\n",
      "Epoch 37/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.2404\n",
      "Epoch 38/100\n",
      "5370/5370 [==============================] - 163s 30ms/step - loss: 0.2133\n",
      "Epoch 39/100\n",
      "5370/5370 [==============================] - 164s 30ms/step - loss: 0.1966\n",
      "Epoch 40/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.2091\n",
      "Epoch 41/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1803\n",
      "Epoch 42/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1757\n",
      "Epoch 43/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1704\n",
      "Epoch 44/100\n",
      "5370/5370 [==============================] - 164s 30ms/step - loss: 0.1424\n",
      "Epoch 45/100\n",
      "5370/5370 [==============================] - 166s 31ms/step - loss: 0.1430\n",
      "Epoch 46/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.1441\n",
      "Epoch 47/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1258\n",
      "Epoch 48/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1274\n",
      "Epoch 49/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1073\n",
      "Epoch 50/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1418\n",
      "Epoch 51/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1001\n",
      "Epoch 52/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0921\n",
      "Epoch 53/100\n",
      "5370/5370 [==============================] - 166s 31ms/step - loss: 0.1379\n",
      "Epoch 54/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0942\n",
      "Epoch 55/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1070\n",
      "Epoch 56/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.2329\n",
      "Epoch 57/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1345\n",
      "Epoch 58/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0755\n",
      "Epoch 59/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0958\n",
      "Epoch 60/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1171\n",
      "Epoch 61/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0747\n",
      "Epoch 62/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0929\n",
      "Epoch 63/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0694\n",
      "Epoch 64/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0910\n",
      "Epoch 65/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.1373\n",
      "Epoch 66/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0979\n",
      "Epoch 67/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.2343\n",
      "Epoch 68/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0525\n",
      "Epoch 69/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0825\n",
      "Epoch 70/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0607\n",
      "Epoch 71/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0729\n",
      "Epoch 72/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0771\n",
      "Epoch 73/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0779\n",
      "Epoch 74/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0545\n",
      "Epoch 75/100\n",
      "5370/5370 [==============================] - 166s 31ms/step - loss: 0.0713\n",
      "Epoch 76/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0581\n",
      "Epoch 77/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0454\n",
      "Epoch 78/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0667\n",
      "Epoch 79/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0469\n",
      "Epoch 80/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0484\n",
      "Epoch 81/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0575\n",
      "Epoch 82/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0616\n",
      "Epoch 83/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0431\n",
      "Epoch 84/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0525\n",
      "Epoch 85/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0527\n",
      "Epoch 86/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0342\n",
      "Epoch 87/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0521\n",
      "Epoch 88/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0604\n",
      "Epoch 89/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0338\n",
      "Epoch 90/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0376\n",
      "Epoch 91/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0465\n",
      "Epoch 92/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0428\n",
      "Epoch 93/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0365\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0550\n",
      "Epoch 95/100\n",
      "5370/5370 [==============================] - 164s 30ms/step - loss: 0.0493\n",
      "Epoch 96/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0402\n",
      "Epoch 97/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0312\n",
      "Epoch 98/100\n",
      "5370/5370 [==============================] - 165s 31ms/step - loss: 0.0692\n",
      "Epoch 99/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0446\n",
      "Epoch 100/100\n",
      "5370/5370 [==============================] - 164s 31ms/step - loss: 0.0277\n"
     ]
    }
   ],
   "source": [
    "notes = get_notes()\n",
    "n_vocab = len(set(notes))\n",
    "network_input,network_output = prepare_sequences(notes,n_vocab)\n",
    "\n",
    "model = create_network(network_input,n_vocab)\n",
    "train(model,network_input,network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
